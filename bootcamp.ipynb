{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN2SRcl+qI5XKgnqEDGYYOe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emanuelebrizzi/bootcamp/blob/main/bootcamp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCJT8cLSu_la",
        "outputId": "37d7a95b-8a94-4252-9150-a2cb5214e00a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TXYDvCvi5XZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ff2759-0430-42e2-bc66-61480ba4056e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import files\n",
        "#import zipfile\n",
        "#import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data upload**\n"
      ],
      "metadata": {
        "id": "vwxvuUJnjbIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Directory path\n",
        "drive_path = \"/content/drive/MyDrive/bootcamp_file\"\n",
        "\n",
        "libpng_path = os.path.join(drive_path, \"LibPNG\")\n",
        "\n",
        "libpng_vuln_path = os.path.join(libpng_path, \"Vulnerable_functions\")\n",
        "libpng_non_vuln_path = os.path.join(libpng_path, \"Non_vulnerable_functions\")\n",
        "\n",
        "vlc_path = os.path.join(drive_path, \"VLC\")\n",
        "\n",
        "vlc_vuln_path = os.path.join(vlc_path, \"Vulnerable_functions\")\n",
        "vlc_non_vuln_path = os.path.join(vlc_path, \"Non_vulnerable_functions\")\n",
        "\n",
        "pidgin_path = os.path.join(drive_path, \"Pidgin\")\n",
        "\n",
        "pidgin_vuln_path = os.path.join(pidgin_path, \"Vulnerable_functions\")\n",
        "pidgin_non_vuln_path = os.path.join(pidgin_path, \"Non_vulnerable_functions\")\n"
      ],
      "metadata": {
        "id": "9bSkiYW8bdvj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_files_from_folder(folder, label):\n",
        "    files = glob.glob(os.path.join(folder, \"*.c\"))\n",
        "    data = []\n",
        "    for file in files:\n",
        "        with open(file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            data.append((f.read(), label, os.path.basename(file)))\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "LuhDeKSyd9Gf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Replace Function names and Variable names**"
      ],
      "metadata": {
        "id": "GrfMYRimjn3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import string\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "PfJOtGKtW-q3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removes comments from C code\n",
        "def remove_comments(code):\n",
        "    code = re.sub(r'//.*', '', code)\n",
        "    code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n",
        "    return code\n",
        "\n",
        "# Extracts variable and function names from C code\n",
        "def extract_identifiers(code):\n",
        "    pattern = re.compile(r'\\b([a-zA-Z_][a-zA-Z0-9_]*)\\b')\n",
        "    keywords = set(['int', 'char', 'float', 'double', 'return', 'if', 'else', 'while', 'for', 'do', 'switch', 'case', 'void'])\n",
        "    identifiers = set(pattern.findall(code)) - keywords\n",
        "    return identifiers\n",
        "\n",
        "# Classifies identifiers as variables or functions\n",
        "def categorize_identifiers(identifiers):\n",
        "    var_counter, fun_counter = 1, 1\n",
        "    replacements = {}\n",
        "    for identifier in identifiers:\n",
        "        if re.search(r'\\b[A-Za-z_][A-Za-z0-9_]*\\s*\\(', identifier):\n",
        "            replacements[identifier] = f'fun_{fun_counter}'\n",
        "            fun_counter += 1\n",
        "        else:\n",
        "            replacements[identifier] = f'var_{var_counter}'\n",
        "            var_counter += 1\n",
        "    return replacements\n",
        "\n",
        "# Replaces variable and function names with new names\n",
        "def replace_identifiers(code, replacements):\n",
        "\n",
        "    for old, new in replacements.items():\n",
        "        code = re.sub(r'\\b' + re.escape(old) + r'\\b', new, code)\n",
        "    return code\n",
        "\n",
        "# Reads a C file, replaces names, and saves the new file\n",
        "def process_c_file(filepath, new_filepath):\n",
        "    with open(filepath, 'r', encoding='Latin-1') as file:\n",
        "        code = file.read()\n",
        "\n",
        "    code_no_comments = remove_comments(code)\n",
        "    identifiers = extract_identifiers(code_no_comments)\n",
        "    replacements = categorize_identifiers(identifiers)\n",
        "    new_code = replace_identifiers(code_no_comments, replacements)\n",
        "    with open(new_filepath, 'w', encoding='Latin-1') as file:\n",
        "        file.write(new_code)\n",
        "\n",
        "# Processes all C files in a directory\n",
        "def process_directory(directory, new_directory_path):\n",
        "    for filepath in Path(directory).glob(\"*.c\"):\n",
        "        new_filepath = os.path.join(new_directory_path, os.path.basename(filepath))\n",
        "        process_c_file(filepath, new_filepath)"
      ],
      "metadata": {
        "id": "zqT_F2_Eoh7P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleanning code:"
      ],
      "metadata": {
        "id": "0X-adtx-kMaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def create_directory(directory_path):\n",
        "    if os.path.exists(directory_path):\n",
        "        shutil.rmtree(directory_path)\n",
        "    os.makedirs(directory_path, exist_ok=True)\n",
        "\n",
        "# Creation modified directory\n",
        "modified_path = os.path.join(drive_path, \"modified_files\")\n",
        "#create_directory(modified_path)\n",
        "\n",
        "libpng_modified = os.path.join(modified_path, \"LibPNG\")\n",
        "#create_directory(libpng_modified)\n",
        "\n",
        "vlc_modified = os.path.join(modified_path, \"VLC\")\n",
        "#create_directory(vlc_modified)\n",
        "\n",
        "pidgin_modified = os.path.join(modified_path, \"Pidgin\")\n",
        "#create_directory(pidgin_modified)\n",
        "\n",
        "libpng_modified_vuln_path = os.path.join(libpng_modified, \"Vulnerable_functions\")\n",
        "#create_directory(libpng_modified_vuln_path)\n",
        "libpng_modified_non_vuln_path = os.path.join(libpng_modified, \"Non_vulnerable_functions\")\n",
        "#create_directory(libpng_modified_non_vuln_path)\n",
        "\n",
        "vlc_modified_vuln_path = os.path.join(vlc_modified, \"Vulnerable_functions\")\n",
        "#create_directory(vlc_modified_vuln_path)\n",
        "vlc_modified_non_vuln_path = os.path.join(vlc_modified, \"Non_vulnerable_functions\")\n",
        "#create_directory(vlc_modified_non_vuln_path)\n",
        "\n",
        "pidgin_modified_vuln_path = os.path.join(pidgin_modified, \"Vulnerable_functions\")\n",
        "#create_directory(pidgin_modified_vuln_path)\n",
        "pidgin_modified_non_vuln_path = os.path.join(pidgin_modified, \"Non_vulnerable_functions\")\n",
        "#create_directory(pidgin_modified_non_vuln_path)\n",
        "\n",
        "#process_directory(libpng_vuln_path, libpng_modified_vuln_path)\n",
        "#process_directory(libpng_non_vuln_path, libpng_modified_non_vuln_path)\n",
        "#process_directory(vlc_vuln_path, vlc_modified_vuln_path)\n",
        "#process_directory(vlc_non_vuln_path, vlc_modified_non_vuln_path)\n",
        "#process_directory(pidgin_vuln_path, pidgin_modified_vuln_path)\n",
        "#process_directory(pidgin_non_vuln_path, pidgin_modified_non_vuln_path)\n"
      ],
      "metadata": {
        "id": "LyBFy5YFsLh9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BLSTM**"
      ],
      "metadata": {
        "id": "5HVkeHkAiXiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense"
      ],
      "metadata": {
        "id": "I_vpja7HQvXW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset preparation"
      ],
      "metadata": {
        "id": "dm5U2rLuQaow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and label data\n",
        "def load_data(directory, label):\n",
        "    data = []\n",
        "    for filename in os.listdir(directory):\n",
        "        with open(os.path.join(directory, filename), 'r') as file:\n",
        "            data.append((file.read(), label))\n",
        "    return data\n",
        "\n",
        "vulnerable_files = load_data(libpng_modified_vuln_path, label=1)\n",
        "non_vulnerable_files = load_data(libpng_modified_non_vuln_path, label=0)\n",
        "\n",
        "# Combine and shuffle dataset\n",
        "dataset = vulnerable_files + non_vulnerable_files\n",
        "np.random.shuffle(dataset)\n",
        "\n",
        "texts, labels = zip(*dataset)"
      ],
      "metadata": {
        "id": "T2SHplrUQYu4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and label data\n",
        "def load_data_directoies(directories, label):\n",
        "    data = []\n",
        "    for directory in directories:  # Iteriamo sulle directory della lista\n",
        "        for filename in os.listdir(directory):  # Ora directory è una stringa\n",
        "            with open(os.path.join(directory, filename), 'r') as file:\n",
        "                data.append((file.read(), label))\n",
        "    return data\n",
        "vulnerable_files = load_data_directoies([libpng_modified_vuln_path, vlc_modified_vuln_path, pidgin_modified_vuln_path], label=1)\n",
        "non_vulnerable_files = load_data_directoies([libpng_modified_non_vuln_path, vlc_modified_non_vuln_path, pidgin_modified_non_vuln_path], label=0)\n",
        "\n",
        "# Combine and shuffle dataset\n",
        "dataset = vulnerable_files + non_vulnerable_files\n",
        "np.random.shuffle(dataset)\n",
        "\n",
        "texts, labels = zip(*dataset)"
      ],
      "metadata": {
        "id": "qrqqOl26TYbe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the data"
      ],
      "metadata": {
        "id": "Rd3Wru_HQ32Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "oXXKaGGbQ1ZN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Pad sequences\n",
        "max_length = 500  # Adjust based on dataset\n",
        "data = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define BLSTM model\n",
        "embedding_dim = 128\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(word_index) + 1, output_dim=embedding_dim, input_length=max_length),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(32, return_sequences=False)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model on training data\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate model on test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "# Predict on test data\n",
        "predictions = model.predict(X_test)\n",
        "y_pred = (predictions > 0.5).astype(int)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScxPHUSJiZco",
        "outputId": "468b7cd7-7a1a-4174-8ca6-d168bf061bd1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9306 - loss: 0.5515 - val_accuracy: 0.9333 - val_loss: 0.2347\n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.9306 - loss: 0.2573 - val_accuracy: 0.9333 - val_loss: 0.2418\n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.9292 - loss: 0.2343 - val_accuracy: 0.9333 - val_loss: 0.2357\n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9284 - loss: 0.2529 - val_accuracy: 0.9333 - val_loss: 0.2364\n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - accuracy: 0.9230 - loss: 0.2421 - val_accuracy: 0.9333 - val_loss: 0.2329\n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.9361 - loss: 0.2294 - val_accuracy: 0.9333 - val_loss: 0.2320\n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.9395 - loss: 0.1932 - val_accuracy: 0.9333 - val_loss: 0.2303\n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - accuracy: 0.9353 - loss: 0.2292 - val_accuracy: 0.9333 - val_loss: 0.2297\n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.9353 - loss: 0.2195 - val_accuracy: 0.9333 - val_loss: 0.2274\n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.9393 - loss: 0.2062 - val_accuracy: 0.9333 - val_loss: 0.2256\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 216ms/step - accuracy: 0.9233 - loss: 0.2137\n",
            "Test Loss: 0.2180604487657547\n",
            "Test Accuracy: 0.9279999732971191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7975061d0680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 222ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7975061d0680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9Foi22mzS-1",
        "outputId": "0270573d-f1c1-4ca7-bdb7-ad442a3d09b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15436"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Pad sequences\n",
        "max_length = 500  # Adjust based on dataset\n",
        "data = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Define K-Fold Cross-Validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "embedding_dim = 128\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(data)):\n",
        "    print(f\"Training on Fold {fold+1}/{k_folds}...\")\n",
        "\n",
        "    X_train, X_test = data[train_index], data[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "    # Creazione del modello\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=len(word_index) + 1, output_dim=embedding_dim, input_length=max_length),\n",
        "        #Bidirectional(LSTM(32, return_sequences=True, dropout=0.3, recurrent_dropout=0.1)),\n",
        "        Bidirectional(LSTM(32, return_sequences=False, dropout=0.3, recurrent_dropout=0.1)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    accuracies.append(accuracy)\n",
        "    print(f\"Fold {fold+1} - Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
        "\n",
        "print(f\"Average Accuracy: {np.mean(accuracies)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQVQ3o_8KBNJ",
        "outputId": "68ec2cd2-f328-469f-def0-3a2ae364ebb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on Fold 1/10...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 1s/step - accuracy: 0.9749 - loss: 0.1023 - val_accuracy: 0.9932 - val_loss: 0.0398\n",
            "Epoch 2/10\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 1s/step - accuracy: 0.9922 - loss: 0.0427 - val_accuracy: 0.9932 - val_loss: 0.0399\n",
            "Epoch 3/10\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 1s/step - accuracy: 0.9917 - loss: 0.0429 - val_accuracy: 0.9932 - val_loss: 0.0387\n",
            "Epoch 4/10\n",
            "\u001b[1m141/348\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:42\u001b[0m 1s/step - accuracy: 0.9921 - loss: 0.0395"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from tabulate import tabulate\n",
        "\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Lista per salvare i nomi dei file nella forma CVE-XXXX-XXXX\n",
        "cve_files = []\n",
        "\n",
        "# Espressione regolare per trovare i nomi compatibili\n",
        "pattern = re.compile(r\"(?i)(?:^|_)cve-(\\d{4})-(\\d{4})\")\n",
        "\n",
        "# Scansiona la directory\n",
        "for file in os.listdir(libpng_modified_vuln_path):\n",
        "    # Cerca nel nome del file\n",
        "    match = pattern.search(file)\n",
        "    if match:\n",
        "        # Formatta il nome nella forma CVE-XXXX-XXXX\n",
        "        formatted_name = f\"CVE-{match.group(1)}-{match.group(2)}\"\n",
        "        cve_files.append(formatted_name)\n",
        "\n",
        "\n",
        "for file in os.listdir(vlc_modified_vuln_path):\n",
        "    # Cerca nel nome del file\n",
        "    match = pattern.search(file)\n",
        "    if match:\n",
        "        # Formatta il nome nella forma CVE-XXXX-XXXX\n",
        "        formatted_name = f\"CVE-{match.group(1)}-{match.group(2)}\"\n",
        "        cve_files.append(formatted_name)\n",
        "\n",
        "\n",
        "for file in os.listdir(pidgin_modified_vuln_path):\n",
        "    # Cerca nel nome del file\n",
        "    match = pattern.search(file)\n",
        "    if match:\n",
        "        # Formatta il nome nella forma CVE-XXXX-XXXX\n",
        "        formatted_name = f\"CVE-{match.group(1)}-{match.group(2)}\"\n",
        "        cve_files.append(formatted_name)\n",
        "\n",
        "\n",
        "\n",
        "print(len(cve_files))\n",
        "\n",
        "\n",
        "# Conta tutte le occorrenze\n",
        "occurrences = Counter(cve_files)\n",
        "\n",
        "# Creiamo una tabella con i dati\n",
        "table_data = [(cve, count) for cve, count in occurrences.items()]\n",
        "\n",
        "# Stampa in formato tabella leggibile\n",
        "print(tabulate(table_data, headers=[\"CVE\", \"Occorrenze\"], tablefmt=\"grid\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sduXWVmiXdzg",
        "outputId": "b17befee-8eef-4da6-fbd9-91ddf1cdbbb3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118\n",
            "+---------------+--------------+\n",
            "| CVE           |   Occorrenze |\n",
            "+===============+==============+\n",
            "| CVE-2015-0973 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2004-0599 |            2 |\n",
            "+---------------+--------------+\n",
            "| CVE-2014-9495 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-3464 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-0408 |            2 |\n",
            "+---------------+--------------+\n",
            "| CVE-2004-0597 |            3 |\n",
            "+---------------+--------------+\n",
            "| CVE-2007-2445 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2006-0481 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2012-3425 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2008-5907 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2018-1378 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-3328 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2007-5269 |            2 |\n",
            "+---------------+--------------+\n",
            "| CVE-2015-8126 |            2 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-2501 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2006-3334 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2007-5629 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2008-6218 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2013-7354 |            2 |\n",
            "+---------------+--------------+\n",
            "| CVE-2015-8472 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2016-1008 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2009-5063 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2013-6954 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2014-0333 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2004-0598 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2007-5267 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2015-7981 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2018-1404 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2015-8540 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2013-7353 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2010-0205 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2006-5793 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-3048 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-2692 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2009-0040 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2006-7244 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2007-5266 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-3045 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-3623 |            3 |\n",
            "+---------------+--------------+\n",
            "| CVE-2008-5276 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2008-1489 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2016-3941 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-0522 |            2 |\n",
            "+---------------+--------------+\n",
            "| CVE-2010-2062 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2007-6682 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2008-5036 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-1684 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2017-8313 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2010-3907 |            2 |\n",
            "+---------------+--------------+\n",
            "| CVE-2017-8310 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2008-1881 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-2587 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2018-1985 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2007-0017 |            3 |\n",
            "+---------------+--------------+\n",
            "| CVE-2014-9598 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2014-1684 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2010-1443 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2010-1444 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2008-4654 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2008-3732 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2018-1151 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2010-3124 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2012-0023 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2008-3794 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2013-1954 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2016-5108 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2013-4388 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2009-2484 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2008-0984 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2014-9597 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-2588 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2010-2937 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2014-9743 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2008-2430 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2015-5949 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2017-8311 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2016-2380 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2010-1624 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2013-0273 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2013-6481 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2009-1376 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-2943 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2016-2375 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2014-3697 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2016-2376 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-3184 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2012-3374 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-4603 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2014-3698 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2009-2694 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2013-0272 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2016-2371 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-4939 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2013-6482 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2016-2374 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2013-6487 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2016-2377 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2013-6489 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2009-3083 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2010-2528 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2011-3594 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2009-3084 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2012-1178 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2008-2927 |            1 |\n",
            "+---------------+--------------+\n",
            "| CVE-2016-2366 |            1 |\n",
            "+---------------+--------------+\n"
          ]
        }
      ]
    }
  ]
}